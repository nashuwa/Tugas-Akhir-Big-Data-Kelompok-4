services:
  #=================================== INFRASTRUCTURE =================================
  postgres:
    container_name: postgres-db
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
      POSTGRES_CONFIG: "-c lock_timeout=30000"
    networks:
      - saham_net
    volumes:
      - postgres-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  mongodb:
    container_name: mongodb-local
    image: mongo:6.0
    ports:
      - "27018:27017"
    networks:
      - saham_net
    volumes:
      - mongodb_data:/data/db
    environment:
      MONGO_INITDB_DATABASE: yfinance_data
    restart: unless-stopped
    healthcheck:
      test: echo 'db.runCommand("ismaster").ismaster' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s

  #=================================== AIRFLOW SERVICES =================================
  airflow-init:
    container_name: airflow-init
    image: apache/airflow:2.6.3
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./output:/opt/airflow/output
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    command: |
      bash -c '
        pip install apache-airflow-providers-docker &&
        airflow db init &&
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com \
          --password admin
      '
    networks:
      - saham_net

  airflow-webserver: 
    container_name: airflow-webserver
    image: apache/airflow:2.6.3
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    networks:
      - saham_net
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./output:/opt/airflow/output
      - /var/run/docker.sock:/var/run/docker.sock
    command: |
      bash -c '
        pip install apache-airflow-providers-docker &&
        airflow webserver
      '
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow 
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    ports:
      - "8080:8080"
    restart: unless-stopped

  airflow-scheduler: 
    container_name: airflow-scheduler
    image: apache/airflow:2.6.3
    command: |
      bash -c '
        pip install apache-airflow-providers-docker &&
        airflow scheduler
      '
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    networks:
      - saham_net
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./output:/opt/airflow/output
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow 
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__PARALLELISM: 24
      AIRFLOW__CORE__DAG_CONCURRENCY: 8
      AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: 3
    restart: unless-stopped

  #=================================== ETL SERVICES (Auto Build - seperti kode temen) =================================
  
  # EXTRACT SERVICE (auto build seperti kode temen)
  extract_yfinance: 
    build:
      context: . 
      dockerfile: extract/Dockerfile
    image: yfinance_extraction:latest
    container_name: extract_yfinance_service
    networks:
      - saham_net
    volumes:
      - ./output:/app/output 
      - ./logs:/app/logs
    environment:
      EXCEL_FILE_PATH: /app/tickers.xlsx
      YFINANCE_OUTPUT_PATH: /app/output/tickers_data.json
      PYTHONUNBUFFERED: 1
    restart: "no"
    profiles: ["manual"]  # Tidak auto start, hanya untuk DAG
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  # LOAD SERVICE (auto build seperti kode temen)  
  load_yfinance:
    build:
      context: .
      dockerfile: load/Dockerfile
    image: yfinance-load:latest
    container_name: load_yfinance_service
    networks:
      - saham_net
    volumes:
      - ./output:/app/output
      - ./logs:/app/logs
    environment:
      MONGO_URI: "mongodb://mongodb-local:27017/"
      MONGO_DB: "yfinance_data"
      INPUT_PATH: "/app/output/tickers_data.json"
      PYTHONUNBUFFERED: 1
    restart: "no"
    profiles: ["manual"]  # Tidak auto start, hanya untuk DAG
    depends_on:
      mongodb:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  #=================================== ETL SERVICES (Optional for traditional mode) =================================
  # extract_yfinance: 
  #   profiles: ["traditional"]  # Only start in traditional mode
  #   build:
  #     context: . 
  #     dockerfile: extract/Dockerfile
  #   image: yfinance_extraction:latest
  #   container_name: extract_yfinance
  #   networks:
  #     - saham_net
  #   volumes:
  #     - ./output:/app/output 
  #     - ./logs:/app/logs
  #   environment:
  #     EXCEL_FILE_PATH: /app/tickers.xlsx
  #     YFINANCE_OUTPUT_PATH: /app/output/tickers_data.json
  #     PYTHONUNBUFFERED: 1
  #   restart: "no"
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 4G
  #         cpus: '2.0'
  #   command: ["python", "yfinance_data_fetcher_5years.py"]

  # load_yfinance:
  #   profiles: ["traditional"]  # Only start in traditional mode
  #   build:
  #     context: .
  #     dockerfile: load/Dockerfile
  #   image: yfinance-load:latest
  #   container_name: load_yfinance
  #   networks:
  #     - saham_net
  #   volumes:
  #     - ./output:/app/output
  #     - ./logs:/app/logs
  #   environment:
  #     MONGO_URI: "mongodb://mongodb-local:27017/"
  #     MONGO_DB: "yfinance_data"
  #     INPUT_PATH: "/app/output/tickers_data.json"
  #     PYTHONUNBUFFERED: 1
  #   restart: "no"
  #   depends_on:
  #     mongodb:
  #       condition: service_healthy
  #     extract_yfinance:
  #       condition: service_completed_successfully
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 3G
  #         cpus: '2.0'
  #   command: ["python", "yfinance-load.py"]

  pipeline-orchestrator:
    profiles: ["traditional"]  # Only start in traditional mode
    image: alpine:latest
    container_name: pipeline_orchestrator
    depends_on:
      extract_yfinance:
        condition: service_completed_successfully
      load_yfinance:
        condition: service_completed_successfully
    volumes:
      - ./output:/output
      - ./logs:/logs
    command: |
      sh -c '
        echo "=========================================="
        echo "üéâ YFINANCE PIPELINE COMPLETED!"
        echo "=========================================="
        echo "‚úÖ Extract: Completed"
        echo "‚úÖ Load: Completed"
        echo ""
        echo "üìÅ Output files:"
        ls -la /output/
        echo ""
        echo "üìä Services available:"
        echo "   ‚Ä¢ Airflow UI: http://localhost:8080 (admin/admin)"
        echo "   ‚Ä¢ MongoDB: localhost:27018 (no auth needed)"
        echo "=========================================="
        sleep 30
      '
    restart: "no"
    networks:
      - saham_net

volumes:
  postgres-db:
    name: postgres_db
  mongodb_data:
    name: mongodb_data

networks:
  saham_net:
    name: saham_net
    driver: bridge